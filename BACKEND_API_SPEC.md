# Backend API Specification

## Overview

The system uses a **fire-and-forget POST request** combined with **Supabase database polling** for result retrieval. This architecture allows for long-running backend processing (up to 10 minutes) without HTTP timeout issues.

### Architecture Flow

1. Frontend sends POST request to `/analyze` (non-blocking)
2. Backend immediately returns (or request is fire-and-forget)
3. Frontend shows 5-minute visual animation
4. Backend processes content in background (up to 10 min)
5. Backend writes results to Supabase database
6. Frontend polls database every 2 seconds for results
7. When results are found, display comprehensive report

## Endpoint

**POST** `https://crew-backend-dxlx.onrender.com/analyze`

The frontend is pre-configured with this production endpoint. No environment variables needed.

## Request Format

```json
{
  "url": "https://www.youtube.com/shorts/xXHUVzYww-E"
}
```

### Request Parameters
- `url` (string, required): The URL to analyze

## Response Format

The backend returns a JSON object with the following structure:

### Example Response

```json
{
  "success": true,
  "message": "Video analysis completed successfully",
  "result": "# Fact-Check Report\n**Content URL:** https://www.youtube.com/shorts/xXHUVzYww-E\n**Content Type:** Video\n**Analysis Date:** 2024-07-30\n\n## 1. EXPLANATION\nThe video depicts a man being apprehended and arrested by police for burglary and theft. However, the prominent \"Sora\" watermark throughout the footage indicates it is an AI-generated simulation. Therefore, the incident portrayed is not a factual recording of a real-world event.\n\n## 2. EVIDENCE\n\n### Claim 1: The incident portrayed in the video is an AI-generated simulation, not a factual recording of a real-world event.\n\n**Status:** TRUE\n\n**Key Evidence:** The video prominently displays a \"Sora\" watermark, featuring a cartoon skull icon, which identifies it as content generated by OpenAI's Sora model. OpenAI's official statements confirm that all Sora outputs carry a visible watermark. Multiple reputable sources, including CNET, The New York Times, and The Los Angeles Times, explicitly state that all videos generated by Sora are artificial, entirely AI-generated, and do not represent real-world footage.\n\n**Sources:**\n- OpenAI - https://openai.com/index/launching-sora-responsibly/\n- CNET - https://www.cnet.com/tech/services-and-software/sora-changed-the-deepfake-game-can-you-tell-whether-a-video-is-real-or-ai/\n- The New York Times - https://www.nytimes.com/2025/10/19/opinion/ai-sora-slop.html\n\n## 3. FINAL VERDICT\nThe claim that the video depicts a real-world incident of an arrest for burglary is FALSE, as the content is an AI-generated simulation.\n\n## 4. CONFIDENCE SCORE\n100%",
  "error": null
}
```

### Response Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `success` | boolean | Yes | Whether the analysis was successful |
| `message` | string | Yes | Human-readable status message |
| `result` | string | Yes (if success) | Markdown-formatted fact-check report |
| `error` | string or null | No | Error message if analysis failed |

### Markdown Report Format

The `result` field contains a markdown-formatted report with the following sections:

1. **Header**: Content URL, Type, and Analysis Date
2. **EXPLANATION**: Summary of the content and key findings
3. **EVIDENCE**: Detailed claims with verification status and sources
4. **FINAL VERDICT**: Overall conclusion about the content
5. **CONFIDENCE SCORE**: Percentage indicating analysis confidence (0-100%)

The frontend automatically parses this markdown and displays it in a beautiful, structured format with:
- Authenticity score visualization
- Sentiment analysis
- Key findings list
- Claims verification with confidence levels
- Recommendations based on the verdict

### Response Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `status` | string | Yes | "success" or "error" |
| `url` | string | Yes | The URL that was processed |
| `content_type` | string | Yes | Type of content processed |
| `report` | object | Yes | The analysis report object |
| `report.summary` | string | No | Brief summary of the content |
| `report.authenticity_score` | number | No | Score from 0 to 1 indicating authenticity |
| `report.sentiment` | string | No | "positive", "negative", "neutral", or "mixed" |
| `report.key_findings` | array | No | List of key findings from the analysis |
| `report.claims` | array | No | Array of claim objects with verification status |
| `report.claims[].claim` | string | Yes | The claim text |
| `report.claims[].verified` | boolean | Yes | Whether the claim was verified |
| `report.claims[].confidence` | number | Yes | Confidence score from 0 to 1 |
| `report.recommendations` | array | No | List of recommendations |
| `report.*` | any | No | Any additional fields will be displayed in the raw data section |

### Error Response

```json
{
  "status": "error",
  "error": "Failed to process URL",
  "message": "The provided URL could not be accessed or is invalid",
  "code": "URL_INVALID"
}
```

## Supabase Database Integration

### Table Schema

The backend should write results to the `video_analysis` table:

```sql
create table public.video_analysis (
    id uuid primary key default gen_random_uuid(),
    url text not null,
    url_status text,
    url_content jsonb,
    inserted_at timestamp with time zone default now()
);
```

### Backend Workflow

1. **Receive POST Request**:
   - Accept URL from `/analyze` endpoint
   - Optional: Return acknowledgment immediately

2. **Insert Initial Record**:
   ```sql
   INSERT INTO video_analysis (url, url_status)
   VALUES ('https://example.com/video', 'processing');
   ```

3. **Process Content**:
   - Download and analyze content
   - Run AI agents for fact-checking
   - Generate markdown report

4. **Update with Results**:
   ```sql
   UPDATE video_analysis
   SET url_status = 'completed',
       url_content = '{
         "success": true,
         "message": "Analysis completed",
         "result": "# Fact-Check Report\\n..."
       }'::jsonb
   WHERE url = 'https://example.com/video'
   AND url_status = 'processing';
   ```

### Database Record Format

The `url_content` JSONB field should contain:

```json
{
  "success": true,
  "message": "Video analysis completed successfully",
  "result": "# Fact-Check Report\n...",
  "error": null
}
```

### Frontend Polling

The frontend queries the database every 2 seconds:

```sql
SELECT * FROM video_analysis
WHERE url = ?
ORDER BY inserted_at DESC
LIMIT 1;
```

When `url_content` is not null, the frontend:
1. Stops polling
2. Parses the markdown `result`
3. Displays the comprehensive report

**Polling Duration**: Up to 10 minutes (300 attempts × 2 seconds)

## Frontend Behavior

1. **On Submit**: 
   - Frontend sends POST request to backend (fire-and-forget)
   - Immediately starts 5-minute visual processing simulation
   - Logs show "Sending request to backend..." → "Request sent to backend"

2. **During Processing (0-5 minutes)**:
   - Beautiful animated UI shows processing steps
   - Realistic progress simulation through all content-specific steps
   - Each step has weighted duration (heavy processes take longer)
   - User sees logs like: "Downloading content", "Running OCR", etc.

3. **After Animation (5-10 minutes)**:
   - Frontend starts polling Supabase database
   - Checks every 2 seconds for results matching the URL
   - Shows "Compiling Report..." screen
   - Logs "Checking database for results..."
   - Every 30 seconds, updates: "Still waiting for results... (X min Y sec)"

4. **When Results Found**:
   - Frontend retrieves data from database
   - Parses markdown report into structured format
   - Displays comprehensive analysis report with:
     - Authenticity score with animated progress bar
     - Summary section
     - Sentiment indicator
     - Key findings list
     - Verified claims with confidence levels
     - Recommendations
     - Raw markdown report (collapsible)
   - Shows completion message: "Analysis completed successfully!"

5. **On Timeout (10 minutes)**:
   - If no results found after 300 attempts (10 min)
   - Shows: "Still compiling the final report..."
   - User can wait longer or check back later

## Testing Without Backend

If the backend/database is not available:
1. Frontend completes the 5-minute visual animation
2. Starts polling but finds no results
3. After 10 minutes, shows: "Still compiling the final report..."
4. User can process another URL or wait longer

## Environment Variables

The frontend is pre-configured with production values. For local development, create `.env.local`:

```bash
# Backend API endpoint
NEXT_PUBLIC_API_URL=http://localhost:8000/analyze

# Supabase Database (optional - defaults are set)
NEXT_PUBLIC_SUPABASE_URL=https://uuocunrkthcixhkgzxeq.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key_here
```

**Production defaults** (no setup needed):
- API URL: `https://crew-backend-dxlx.onrender.com/analyze`
- Supabase: Pre-configured with production credentials

## Example Backend Implementation (Python/FastAPI)

### With Supabase Integration

```python
from fastapi import FastAPI, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from supabase import create_client, Client
import os
import json

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Adjust for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Supabase client (use service role key for backend)
supabase: Client = create_client(
    os.environ.get("SUPABASE_URL"),
    os.environ.get("SUPABASE_SERVICE_KEY")  # Service role, not anon key
)

class AnalyzeRequest(BaseModel):
    url: str

async def process_content_async(url: str):
    """Background task to process content and update database"""
    try:
        # Step 1: Insert initial record
        supabase.table("video_analysis").insert({
            "url": url,
            "url_status": "processing"
        }).execute()
        
        # Step 2: Process the content (your AI agents, analysis, etc.)
        # This is where you'd call your content analysis pipeline
        result_markdown = analyze_content(url)  # Your function
        
        # Step 3: Update database with results
        supabase.table("video_analysis").update({
            "url_status": "completed",
            "url_content": {
                "success": True,
                "message": "Video analysis completed successfully",
                "result": result_markdown,
                "error": None
            }
        }).eq("url", url).eq("url_status", "processing").execute()
        
    except Exception as e:
        # Update with error status
        supabase.table("video_analysis").update({
            "url_status": "error",
            "url_content": {
                "success": False,
                "message": f"Analysis failed: {str(e)}",
                "result": None,
                "error": str(e)
            }
        }).eq("url", url).execute()

def analyze_content(url: str) -> str:
    """
    Your actual content analysis logic goes here.
    This should return a markdown-formatted fact-check report.
    """
    # Example: Download content, run OCR, fact-check, etc.
    return """# Fact-Check Report
**Content URL:** {url}
**Content Type:** Video
**Analysis Date:** 2024-10-29

## 1. EXPLANATION
Analysis summary here...

## 2. EVIDENCE
Claims and verification here...

## 3. FINAL VERDICT
Conclusion here...

## 4. CONFIDENCE SCORE
95%
""".format(url=url)

@app.post("/analyze")
async def analyze_url(request: AnalyzeRequest, background_tasks: BackgroundTasks):
    """
    Endpoint that receives URL and processes it in background.
    Returns immediately while processing continues.
    """
    # Add processing to background tasks
    background_tasks.add_task(process_content_async, request.url)
    
    # Return immediately
    return {
        "status": "accepted",
        "message": "Processing started",
        "url": request.url
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### Key Points

1. **Background Processing**: Uses FastAPI's `BackgroundTasks` to process asynchronously
2. **Supabase Service Key**: Backend should use service role key (not anon key) for full access
3. **Status Updates**: Updates database status from "processing" → "completed" or "error"
4. **Immediate Response**: Returns HTTP 200 immediately, processing continues in background

## Notes

- The frontend animation takes approximately 10-15 seconds to complete
- Backend processing should ideally complete within this timeframe for best UX
- If backend takes longer, the frontend will wait and show the report when ready
- All report fields are optional except `status` and `url`
- The UI gracefully handles missing fields by not displaying those sections

