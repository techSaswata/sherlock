# Backend API Specification

## Overview
The URL processor now uses a POST request instead of WebSockets. The frontend will display a simulated processing animation while waiting for the backend response.

## Endpoint

**POST** `https://crew-backend-dxlx.onrender.com/analyze`

The frontend is pre-configured with this production endpoint. No environment variables needed.

## Request Format

```json
{
  "url": "https://www.youtube.com/shorts/xXHUVzYww-E"
}
```

### Request Parameters
- `url` (string, required): The URL to analyze

## Response Format

The backend returns a JSON object with the following structure:

### Example Response

```json
{
  "success": true,
  "message": "Video analysis completed successfully",
  "result": "# Fact-Check Report\n**Content URL:** https://www.youtube.com/shorts/xXHUVzYww-E\n**Content Type:** Video\n**Analysis Date:** 2024-07-30\n\n## 1. EXPLANATION\nThe video depicts a man being apprehended and arrested by police for burglary and theft. However, the prominent \"Sora\" watermark throughout the footage indicates it is an AI-generated simulation. Therefore, the incident portrayed is not a factual recording of a real-world event.\n\n## 2. EVIDENCE\n\n### Claim 1: The incident portrayed in the video is an AI-generated simulation, not a factual recording of a real-world event.\n\n**Status:** TRUE\n\n**Key Evidence:** The video prominently displays a \"Sora\" watermark, featuring a cartoon skull icon, which identifies it as content generated by OpenAI's Sora model. OpenAI's official statements confirm that all Sora outputs carry a visible watermark. Multiple reputable sources, including CNET, The New York Times, and The Los Angeles Times, explicitly state that all videos generated by Sora are artificial, entirely AI-generated, and do not represent real-world footage.\n\n**Sources:**\n- OpenAI - https://openai.com/index/launching-sora-responsibly/\n- CNET - https://www.cnet.com/tech/services-and-software/sora-changed-the-deepfake-game-can-you-tell-whether-a-video-is-real-or-ai/\n- The New York Times - https://www.nytimes.com/2025/10/19/opinion/ai-sora-slop.html\n\n## 3. FINAL VERDICT\nThe claim that the video depicts a real-world incident of an arrest for burglary is FALSE, as the content is an AI-generated simulation.\n\n## 4. CONFIDENCE SCORE\n100%",
  "error": null
}
```

### Response Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `success` | boolean | Yes | Whether the analysis was successful |
| `message` | string | Yes | Human-readable status message |
| `result` | string | Yes (if success) | Markdown-formatted fact-check report |
| `error` | string or null | No | Error message if analysis failed |

### Markdown Report Format

The `result` field contains a markdown-formatted report with the following sections:

1. **Header**: Content URL, Type, and Analysis Date
2. **EXPLANATION**: Summary of the content and key findings
3. **EVIDENCE**: Detailed claims with verification status and sources
4. **FINAL VERDICT**: Overall conclusion about the content
5. **CONFIDENCE SCORE**: Percentage indicating analysis confidence (0-100%)

The frontend automatically parses this markdown and displays it in a beautiful, structured format with:
- Authenticity score visualization
- Sentiment analysis
- Key findings list
- Claims verification with confidence levels
- Recommendations based on the verdict

### Response Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `status` | string | Yes | "success" or "error" |
| `url` | string | Yes | The URL that was processed |
| `content_type` | string | Yes | Type of content processed |
| `report` | object | Yes | The analysis report object |
| `report.summary` | string | No | Brief summary of the content |
| `report.authenticity_score` | number | No | Score from 0 to 1 indicating authenticity |
| `report.sentiment` | string | No | "positive", "negative", "neutral", or "mixed" |
| `report.key_findings` | array | No | List of key findings from the analysis |
| `report.claims` | array | No | Array of claim objects with verification status |
| `report.claims[].claim` | string | Yes | The claim text |
| `report.claims[].verified` | boolean | Yes | Whether the claim was verified |
| `report.claims[].confidence` | number | Yes | Confidence score from 0 to 1 |
| `report.recommendations` | array | No | List of recommendations |
| `report.*` | any | No | Any additional fields will be displayed in the raw data section |

### Error Response

```json
{
  "status": "error",
  "error": "Failed to process URL",
  "message": "The provided URL could not be accessed or is invalid",
  "code": "URL_INVALID"
}
```

## Frontend Behavior

1. **On Submit**: 
   - Frontend immediately starts POST request to backend
   - Simultaneously starts the visual processing simulation
   - Logs show "Sending request to backend..."

2. **During Processing**:
   - Beautiful animated UI shows processing steps
   - Fake progress simulation runs through all steps
   - If backend is unavailable, shows "Backend unavailable, running in demo mode"

3. **On Completion**:
   - Frontend waits for backend response
   - When response arrives, displays comprehensive analysis report with:
     - Authenticity score with animated progress bar
     - Summary section
     - Sentiment indicator
     - Key findings list
     - Claims verification with confidence levels
     - Recommendations
     - Raw JSON data (collapsible)
   - Download button to export report as JSON

## Testing Without Backend

If the backend is not available, the frontend will:
1. Show a warning: "Backend unavailable, running in demo mode"
2. Complete the visual animation
3. Show completion message without the detailed report
4. Allow user to process another URL

## Environment Variables

Add to your `.env.local`:

```bash
NEXT_PUBLIC_API_URL=http://localhost:8000/api/process
```

Or use the default: `http://localhost:8000/api/process`

## Example Backend Implementation (Python/FastAPI)

```python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import time

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Your Next.js app
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ProcessRequest(BaseModel):
    url: str
    content_type: str
    timestamp: str

@app.post("/api/process")
async def process_url(request: ProcessRequest):
    # Simulate processing time
    time.sleep(10)  # Your actual processing logic here
    
    # Return analysis report
    return {
        "status": "success",
        "url": request.url,
        "content_type": request.content_type,
        "report": {
            "summary": "Analysis complete. This is a demo response.",
            "authenticity_score": 0.85,
            "sentiment": "positive",
            "key_findings": [
                "Content appears authentic",
                "No manipulation detected"
            ],
            "claims": [
                {
                    "claim": "Example claim from the content",
                    "verified": True,
                    "confidence": 0.9
                }
            ],
            "recommendations": [
                "Verify with additional sources",
                "Check for updates"
            ]
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

## Notes

- The frontend animation takes approximately 10-15 seconds to complete
- Backend processing should ideally complete within this timeframe for best UX
- If backend takes longer, the frontend will wait and show the report when ready
- All report fields are optional except `status` and `url`
- The UI gracefully handles missing fields by not displaying those sections

